import os
import csv
import psycopg2
from dotenv import load_dotenv
from pathlib import Path

# Carrega variáveis do .env
load_dotenv()  # procura automaticamente um arquivo .env na raiz

# Pegue a connection string completa do .env, por exemplo:

DB_NAME= os.getenv("POSTGRES_DB")
POOLER_TENANT_ID= os.getenv("POOLER_TENANT_ID")
POSTGRES_PASSWORD= os.getenv("POSTGRES_PASSWORD")
POSTGRES_PORT= os.getenv("POSTGRES_PORT")
POSTGRES_HOST= "0.0.0.0" #os.getenv("POSTGRES_HOST")
POSTGRES_DB= os.getenv("POSTGRES_DB")
DATABASE_URL=f"postgres://{DB_NAME}.{POOLER_TENANT_ID}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"
FOLDER_TABLES="./tables"

table_schemes = {
"app_configs":
"""
create table public.app_configs (
id bigint generated by default as identity not null,
created_at timestamp with time zone not null default now(),
time_check_invoices_seconds bigint null,
time_send_invoices_seconds bigint null,
constraint app_configs_pkey primary key (id)
) TABLESPACE pg_default;
"""   
,
"accounts":
"""
create table public.accounts (
  created_at timestamp with time zone not null default now(),
  email text not null,
  display_name text null,
  uid uuid null default gen_random_uuid (),
  phone text null,
  confirmed boolean not null default false,
  enable_camera_loop boolean not null default true,
  constraint accounts_pkey primary key (email),
  constraint users_email_key unique (email),
  constraint users_uid_fkey foreign KEY (uid) references auth.users (id) on update CASCADE on delete CASCADE
) TABLESPACE pg_default;
""" 
,
"credentials":
"""
create table public.credentials (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  cpf text null,
  password text null,
  name text null,
  entity_id bigint null,
  constraint credentials_pkey primary key (id)
) TABLESPACE pg_default;
"""   
,

"employees":
"""
create table public.employees (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  email text not null,
  position text null,
  entity_id bigint not null,
  constraint employees_pkey primary key (id)
) TABLESPACE pg_default;
""" 
,

"entities":
"""
create table public.entities (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  name text null,
  name_id text null,
  responsible_email text not null default 'izaias.junior@alu.ufc.br'::text,
  enabled boolean not null default false,
  cnpj text not null,
  constraint entities_pkey primary key (id),
  constraint entities_responsible_email_fkey foreign KEY (responsible_email) references accounts (email) on update CASCADE on delete CASCADE,
  constraint entities_enabled_check check ((enabled = any (array[true, false])))
) TABLESPACE pg_default;
"""
,

"invoices":
"""
create table public.invoices (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone null default now(),
  code text not null,
  entity_id bigint not null,
  valid boolean null default false,
  status text null default 'UNSUBMITTED'::text,
  status_message text null,
  original_code text null,
  cad_email text null default 'Não logado'::text,
  uf text null,
  year text null,
  month text null,
  cnpj text null,
  "modelSat" text null,
  "numberSat" text null,
  coo text null,
  "authCode" text null,
  "emitForm" text null,
  "aleatoryNumber" text null,
  "checkDigit" text null,
  constraint invoices_pkey primary key (id),
  constraint invoices_code_key unique (code)
) TABLESPACE pg_default;

create index IF not exists idx_invoices_entity_id on public.invoices using btree (entity_id) TABLESPACE pg_default;

create index IF not exists idx_invoices_created_at on public.invoices using btree (created_at) TABLESPACE pg_default;

create index IF not exists idx_invoices_entity_id_created_at on public.invoices using btree (entity_id, created_at) TABLESPACE pg_default;
"""   
,

"root":
"""
create table public.root (
  id bigint generated by default as identity not null,
  created_at timestamp with time zone not null default now(),
  uid uuid not null default gen_random_uuid (),
  constraint root_pkey primary key (id),
  constraint root_uid_key unique (uid),
  constraint root_uid_fkey foreign KEY (uid) references auth.users (id)
) TABLESPACE pg_default;
"""
,
"donors":
"""
create table public.donors (
  id uuid not null default gen_random_uuid (),
  created_at timestamp with time zone not null default now(),
  "fullName" text null,
  "motherName" text null,
  info text null,
  cpf numeric null,
  email text not null,
  whatsapp numeric null,
  birthday date null,
  "fullAddress" text null,
  "passGov" text null,
  entity_id bigint not null,
  entity_name text null,
  "isRegistered" boolean not null default false,
  constraint donors_pkey primary key (id, email),
  constraint donors_entity_id_fkey foreign KEY (entity_id) references entities (id)
) TABLESPACE pg_default;
"""
}

# Conecta ao PostgreSQL usando a URL completa
conn = psycopg2.connect(DATABASE_URL)
cur = conn.cursor()

folder_tables = Path(FOLDER_TABLES)

# Caminho completo dos arquivos apenas na pasta
csv_files = [str(f) for f in folder_tables.iterdir() if f.is_file()]

# for csv_file in csv_files:
for table_name, table_scheme in table_schemes.items():
    path_csv_file = Path(f"{FOLDER_TABLES}/{table_name}_rows.csv")
    
    print(f"\nExecuting for table {path_csv_file}:")

    # 1️⃣ Criar a tabela
    create_table_sql = table_scheme
    print(f"creating table ...")

    try:
        cur.execute(create_table_sql)
        conn.commit()

        print("Inserting data ...")
        with open(path_csv_file, newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames  # lista com os nomes das colunas do CSV
            if not headers:
                print("CSV vazio ou sem header, pulando.")
                continue

            rows = []
            for row in reader:
                # gera uma tupla de valores na ordem do header
                values = tuple(row.get(col) if row.get(col) != '' else None for col in headers)
                rows.append(values)

            # Monta dinamicamente o INSERT
            columns_sql = ", ".join([f'"{h}"' for h in headers])  # protege nomes de colunas
            placeholders = ", ".join(["%s"] * len(headers))

            insert_sql = f"""
            INSERT INTO public.{table_name} ({columns_sql})
            VALUES ({placeholders})
            ON CONFLICT DO NOTHING;
            """

            if rows:
                cur.executemany(insert_sql, rows)
                conn.commit()
                print(f"{len(rows)} linhas inseridas em '{table_name}'.")
            else:
                print("Nenhuma linha para inserir.")
        
    except Exception as e:
        conn.commit()
        print(e)
        
cur.close()
conn.close()


